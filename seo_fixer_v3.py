import os
import datetime
from bs4 import BeautifulSoup

# ========== æ—¥å¿—åˆå§‹åŒ– ==========
log_lines = []
def log(msg):
    print(msg)
    log_lines.append(msg)

# ========== æ ¸å¿ƒä¿®å¤é€»è¾‘ ==========
def fix_html_file(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        soup = BeautifulSoup(content, 'html.parser')

        # è·å– <head> æ ‡ç­¾
        head_tag = soup.head
        if head_tag is None:
            log(f"âŒ æ— æ³•ä¿®å¤ï¼š{filepath}ï¼ˆæ²¡æœ‰<head>æ ‡ç­¾ï¼‰")
            return

        # æ£€æŸ¥å¹¶æ·»åŠ  canonical æ ‡ç­¾
        canonical_exists = soup.find("link", {"rel": "canonical"})
        if not canonical_exists:
            canonical_link = soup.new_tag("link", rel="canonical", href=f"./{os.path.basename(filepath)}")
            head_tag.append(canonical_link)
            log(f"ğŸ”— æ·»åŠ  canonical: ./{os.path.basename(filepath)}")

        # æ£€æŸ¥å¹¶æ·»åŠ ç»“æ„åŒ– schemaï¼ˆç®€åŒ–ç‰ˆï¼‰
        schema_exists = soup.find("script", {"type": "application/ld+json"})
        if not schema_exists:
            schema_tag = soup.new_tag("script", type="application/ld+json")
            schema_tag.string = """{
  "@context": "https://schema.org",
  "@type": "WebPage",
  "name": "Sample Page",
  "description": "Auto SEO Fixer Page"
}"""
            head_tag.append(schema_tag)
            log(f"ğŸ§© æ·»åŠ  schema æ ‡è®°")

        # ä¿å­˜ä¿®å¤åçš„å†…å®¹
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(str(soup))

        log(f"âœ… ä¿®å¤å®Œæˆï¼š{filepath}")

    except Exception as e:
        log(f"âŒ é”™è¯¯å¤„ç†æ–‡ä»¶ {filepath}: {e}")

# ========== èµ„æºæ–‡ä»¶æ¸…ç† ==========
def delete_empty_or_redirect_html(folder):
    count = 0
    for root, _, files in os.walk(folder):
        for file in files:
            if file.endswith('.html'):
                filepath = os.path.join(root, file)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        html = f.read()
                        if 'window.location.href' in html or len(html.strip()) < 20:
                            os.remove(filepath)
                            log(f"ğŸ—‘ï¸ åˆ é™¤å¤±æ•ˆèµ„æºï¼š{file}")
                            count += 1
                except:
                    continue
    return count

# ========== éå†æ‰€æœ‰ HTML ==========
def walk_and_fix(folder):
    for root, _, files in os.walk(folder):
        for file in files:
            if file.endswith('.html'):
                full_path = os.path.join(root, file)
                fix_html_file(full_path)

# ========== ä¸»ç¨‹åºå…¥å£ ==========
if __name__ == "__main__":
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log(f"ğŸ”§ SEO è‡ªåŠ¨ä¿®å¤å¯åŠ¨ï¼š{now}\n")

    current_dir = os.getcwd()

    # æ¸…ç†æ— æ•ˆèµ„æº
    removed = delete_empty_or_redirect_html(current_dir)
    log(f"\nâœ… å…±æ¸…ç†æ— æ•ˆèµ„æºæ–‡ä»¶ï¼š{removed} ä¸ª\n")

    # å¼€å§‹ä¿®å¤
    walk_and_fix(current_dir)

    # è¾“å‡ºæ—¥å¿—æ–‡ä»¶
    log_path = os.path.join(current_dir, "seo_fixer_log.txt")
    with open(log_path, "w", encoding="utf-8") as f:
        f.write("\n".join(log_lines))

    log(f"\nğŸ“„ æ—¥å¿—å·²ä¿å­˜è‡³ï¼š{log_path}")
    log("âœ… æ‰€æœ‰ä¿®å¤ä»»åŠ¡å®Œæˆï¼")
